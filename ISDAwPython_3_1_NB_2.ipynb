{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "ISDAwPython_3_1_NB_2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sigvehaug/ISDAwPython_day3.1/blob/main/ISDAwPython_3_1_NB_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YhbqBJblQ_F"
      },
      "source": [
        "Statistics with Python, 2021-03-08, S. Haug, University of Bern. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcl8WzDAlQ_O"
      },
      "source": [
        "# Parameter estimation / regression\n",
        "\n",
        "**Average expected study time :** 3x45 min (depending on your background)\n",
        "\n",
        "**Learning outcomes :**\n",
        "\n",
        "- Know what is meant with parameter estimation and regression\n",
        "- Perform linear regression with Python by example\n",
        "- Perform non-linear regression with Python by example\n",
        "- Know what non-parametric regression is \n",
        "\n",
        "**Main python module used**\n",
        "- the Scipy.stat module https://docs.scipy.org/doc/scipy/reference/stats.html\n",
        "\n",
        "**Content :**\n",
        "\n",
        "3.0 Regression - Situation<br>\n",
        "3.1 Linear regression<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWWm_LjnlQ_Q"
      },
      "source": [
        "# 3.0 Regression - Situation\n",
        "\n",
        "We have data and want to extract model paramters from that data. An example would be to estimate the mean and the standard deviation, assuming a normal distribution. Another one would be to fit a straight line. For historical reasons this kind of analysis is often called regression. Some scientists just say fitting (model parameters to the data).\n",
        "\n",
        "We distinguish between parametric and non-parametric models. A line and the normal distribution are both parametric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A7uSyDdlQ_R"
      },
      "source": [
        "## 3.1 About linear Regression\n",
        "\n",
        "Linear regression means fitting linear parameters to a set of data points (x,y). x and y may be vectors. You may consider this as the simplest case of Machine Learning (see Module 3). Example, a line is described by\n",
        "\n",
        "$$y = ax + b$$\n",
        "\n",
        "Thus two parameters a (slope) and b (intersection with y axis) can be fitted to (x,y).\n",
        "\n",
        "There are different fitting methods, mostly least squares or maximum likelihood are used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYqBljb1lQ_R"
      },
      "source": [
        "## 3.2 Linear regression with scipy.stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3lCmTW-lQ_R"
      },
      "source": [
        "Import the Python libraries we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4LYPtwHlQ_S"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy.stats as stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9g623m1lQ_S"
      },
      "source": [
        "Read the data from file and do a linear regression for a line in the plength-pwidth space of the setosa sample. We use https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html, using least squares. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxLwNl9qlQ_T"
      },
      "source": [
        "url = 'https://www.openml.org/data/get_csv/61/dataset_61_iris.arff'\n",
        "df = pd.read_csv(url)\n",
        "#df_set = df[df['species']=='Iris-versicolor']\n",
        "df_set = df[df['class']=='Iris-setosa']\n",
        "plengths = df_set['petallength']\n",
        "pwidths  = df_set['petalwidth']\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(plengths,pwidths)\n",
        "print (slope, intercept, std_err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZwv1awylQ_U"
      },
      "source": [
        "The number of digits is ridiculous. Let's print it better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnsQei9flQ_U"
      },
      "source": [
        "print ('Gradient = %1.2f +- %1.2f' % (slope,std_err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo3VIQUxlQ_V"
      },
      "source": [
        "Let's look at the scatter plot to see if this makes sense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emvgZU4-lQ_V"
      },
      "source": [
        "ax = df_set.plot(x='petallength',y='petalwidth',kind=\"scatter\",c='c')\n",
        "plt.plot(plengths, intercept + slope*plengths, 'b', label='Fitted line')\n",
        "#plt.plot(plengths, intercept + (slope+0.08)*plengths, 'r', label='Fitted line')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmIO7YhwlQ_V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ateyd_NPlQ_V"
      },
      "source": [
        "By eye it is hard to say how good this fit is. Try the same regression  with versicolor. The result may be a bit clearer.\n",
        "\n",
        "We now have a model, a straight line, whose shape we have chosen, but whose parameters (slope and intersection) have been estimated/fitted from data with the least squares method. It tells us that pwidth of a leaf is plength x slope ( f(plength) = a x slope). So we can do interpolation and extrapolation, i.e. get the pwidth at any plength.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUr60KbxlQ_W"
      },
      "source": [
        "## 3.3 Fitting the exponential p.d.f.\n",
        "\n",
        "With scale $\\beta$ and location $\\mu$\n",
        "\n",
        "$$f(x)=\\frac{1}{\\beta} e^{-(x-\\mu)/\\beta}     ,  x \\ge \\mu;\\beta>0$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV3BNhc8lQ_W"
      },
      "source": [
        "# Let us fit data to an exponential distribution\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "# First generate a data set from an exponential distribution\n",
        "x = stats.expon.rvs(size=100) #  scale = 0.0, location = 0.00, 1000 variates\n",
        "ax.hist(x, density=True, histtype='stepfilled', alpha=0.2)\n",
        "# Fit scale and location to the histogram/data\n",
        "loc, scale = stats.expon.fit(x) # ML estimator scale, lambda * exp(-lambda * x), scale =1/lambda\n",
        "print(' Location = %1.2f , Scale = %1.2f' % (loc,scale)) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzS27I4elQ_X"
      },
      "source": [
        "This fit method is poor in the sense that it doesn't return uncertainties on the fitted values. This we normally want to know. The curve_fit method below also returns the uncertainties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbAm9K2hlQ_X"
      },
      "source": [
        "## 3.4 Fitting your own defined function\n",
        "\n",
        "If a line is not streight it is curved. There are many mathematical functions whose parameters we can try to fit to experimental data points. Some examples: Polynominals (first order is linear regression, second order is a parabola etc), exponential functions, normal function, sindoial wave function etc. You need to choose an approriate shape/function to obtain a good result. \n",
        "\n",
        "With the Scipy.stat module we can look for preprogrammed functions (in principle you can program your own function whose parameters you want to fit too): https://docs.scipy.org/doc/scipy/reference/stats.html. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNuGd0PUlQ_X"
      },
      "source": [
        "The scipy.optimize module provides a more general non-linear least squares fit. Look at and play with this example. It is complex and you will probably need some time testing, googling etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGm7EBC6lQ_Y"
      },
      "source": [
        "from scipy.optimize import curve_fit\n",
        "\n",
        "def func(x, a, b, c):\n",
        "     return a * np.exp(-b * x) + c\n",
        "\n",
        "xdata = np.linspace(0, 4, 50) # \n",
        "y = func(xdata, 2.5, 1.3, 0.5)\n",
        "plt.plot(xdata, y, 'g-', label='Generated data')\n",
        "np.random.seed(1729)\n",
        "y_noise = 0.2 * np.random.normal(size=xdata.size)\n",
        "ydata = y + y_noise\n",
        "plt.plot(xdata, ydata, 'b-', label='Generated data with noise')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVL2QyYolQ_Y"
      },
      "source": [
        "popt, pcov = curve_fit(func, xdata, ydata)\n",
        "print(popt)\n",
        "perr = np.sqrt(np.diag(pcov)) # Standard deviation = square root of the variance being on the diagonal of the covariance matrix\n",
        "plt.plot(xdata, func(xdata, *popt), 'r-',label= \\\n",
        "         'fit: a=%5.3f +- %5.3f, \\n b=%5.3f +- %5.3f, \\n c=%5.3f +-%5.3f' % \\\n",
        "         (popt[0],perr[0],popt[1],perr[1],popt[2],perr[2]))\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.plot(xdata, ydata, 'b+', label='Data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "perr = np.sqrt(np.diag(pcov)) # Standard deviation = square root of the variance being on the diagonal of the covariance matrix\n",
        "perr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYRTp9hqnDdh"
      },
      "source": [
        "## 3.5 Regression with statsmodels\n",
        "\n",
        "The regression methods in scipy.stats don't give very rich output. In particular, one often would like two know more about the uncertainties on the fitted parameters. The **statsmodels** library is in this sense more powerful. Let us look at one example.\n",
        "\n",
        "statsmodels documentation: https://www.statsmodels.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZPCJnSin9Uu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
        "\n",
        "np.random.seed(9876789)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLdFcuC2oYU-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVsyIbjOoHVH"
      },
      "source": [
        "# pwidths and plenghts we extracted from the Iris set above\n",
        "model = sm.OLS(pwidths, plengths)\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rKCvtWclQ_Z"
      },
      "source": [
        "## 3.6 Comment on non-parametric regression\n",
        "\n",
        "So far we have used functions (models) with some predefined shape/form. The parameters we fitted to data. If we have no clue about the form, we may try to fit with non-parametric methods. However, these require more data as also the shape needs to guessed or fitted from the data. So normally a non-parametric method gives poorer results. \n",
        "\n",
        "There are several ways to do this in Python. You make look at this if you are interested:\n",
        "\n",
        "https://pythonhosted.org/PyQt-Fit/NonParam_tut.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmboZs1_q8ll"
      },
      "source": [
        "## 3.7 Exercise\n",
        "\n",
        "Now fit a line for the correlation between length and width for the virginica class. Do it both with stats.linregress and the statsmodules-OLS method. If you have time, try to plot the fitted lines, also with the uncertainties given by the fits, and the data points to see if your fits make sense. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-5hb-oMnxSX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}